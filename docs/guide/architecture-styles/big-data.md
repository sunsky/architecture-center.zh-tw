---
title: 巨量資料架構樣式
description: 說明 Azure 上巨量資料架構的優點、挑戰和最佳作法
author: MikeWasson
ms.openlocfilehash: d76192cf2fc680497ece0123ef412971c025f9dc
ms.sourcegitcommit: 8ec48a0e2c080c9e2e0abbfdbc463622b28de2f2
ms.translationtype: HT
ms.contentlocale: zh-TW
ms.lasthandoff: 08/18/2018
ms.locfileid: "43016050"
---
# <a name="big-data-architecture-style"></a><span data-ttu-id="65419-103">巨量資料架構樣式</span><span class="sxs-lookup"><span data-stu-id="65419-103">Big data architecture style</span></span>

<span data-ttu-id="65419-104">巨量資料架構的設計，可處理對於傳統資料庫系統而言太大或太複雜之資料的擷取、處理和分析。</span><span class="sxs-lookup"><span data-stu-id="65419-104">A big data architecture is designed to handle the ingestion, processing, and analysis of data that is too large or complex for traditional database systems.</span></span>

![](./images/big-data-logical.svg)

 <span data-ttu-id="65419-105">巨量資料的解決方案通常會涉及一或多個下列類型的工作負載：</span><span class="sxs-lookup"><span data-stu-id="65419-105">Big data solutions typically involve one or more of the following types of workload:</span></span>

- <span data-ttu-id="65419-106">待用之巨量資料來源的批次處理。</span><span class="sxs-lookup"><span data-stu-id="65419-106">Batch processing of big data sources at rest.</span></span>
- <span data-ttu-id="65419-107">移動中之巨量資料的即時處理。</span><span class="sxs-lookup"><span data-stu-id="65419-107">Real-time processing of big data in motion.</span></span>
- <span data-ttu-id="65419-108">巨量資料的互動式探索。</span><span class="sxs-lookup"><span data-stu-id="65419-108">Interactive exploration of big data.</span></span>
- <span data-ttu-id="65419-109">預測性分析和機器學習。</span><span class="sxs-lookup"><span data-stu-id="65419-109">Predictive analytics and machine learning.</span></span>

<span data-ttu-id="65419-110">巨量資料的架構大多包括下列的部分或所有元件：</span><span class="sxs-lookup"><span data-stu-id="65419-110">Most big data architectures include some or all of the following components:</span></span>

- <span data-ttu-id="65419-111">**資料來源**：所有的巨量資料解決方案都是從一個或多個資料來源來做為開端。</span><span class="sxs-lookup"><span data-stu-id="65419-111">**Data sources**: All big data solutions start with one or more data sources.</span></span> <span data-ttu-id="65419-112">範例包括：</span><span class="sxs-lookup"><span data-stu-id="65419-112">Examples include:</span></span>

    - <span data-ttu-id="65419-113">應用程式資料存放區，例如關聯式資料庫。</span><span class="sxs-lookup"><span data-stu-id="65419-113">Application data stores, such as relational databases.</span></span>
    - <span data-ttu-id="65419-114">應用程式所產生的靜態檔案，例如 Web 伺服器記錄檔。</span><span class="sxs-lookup"><span data-stu-id="65419-114">Static files produced by applications, such as web server log files.</span></span>
    - <span data-ttu-id="65419-115">即時資料來源，例如 IoT 裝置。</span><span class="sxs-lookup"><span data-stu-id="65419-115">Real-time data sources, such as IoT devices.</span></span>

- <span data-ttu-id="65419-116">**資料存放區**：要進行批次處理作業的資料通常儲存在分散式檔案存放區，以便能夠保存大量具有不同格式的大型檔案。</span><span class="sxs-lookup"><span data-stu-id="65419-116">**Data storage**: Data for batch processing operations is typically stored in a distributed file store that can hold high volumes of large files in various formats.</span></span> <span data-ttu-id="65419-117">這種存放區通常稱為「資料湖」。</span><span class="sxs-lookup"><span data-stu-id="65419-117">This kind of store is often called a *data lake*.</span></span> <span data-ttu-id="65419-118">可供實作此儲存體的選項包含 Azure Data Lake Store 或 Azure 儲存體中的 Blob 容器。</span><span class="sxs-lookup"><span data-stu-id="65419-118">Options for implementing this storage include Azure Data Lake Store or blob containers in Azure Storage.</span></span> 

- <span data-ttu-id="65419-119">**批次處理**：由於資料集是如此龐大，巨量資料解決方案通常必須使用需要長時間執行的批次作業來處理資料檔案，以便篩選、彙總和準備資料以供分析。</span><span class="sxs-lookup"><span data-stu-id="65419-119">**Batch processing**: Because the data sets are so large, often a big data solution must process data files using long-running batch jobs to filter, aggregate, and otherwise prepare the data for analysis.</span></span> <span data-ttu-id="65419-120">這些作業通常涉及讀取原始程式檔、加以處理，然後將輸出寫入至新的檔案。</span><span class="sxs-lookup"><span data-stu-id="65419-120">Usually these jobs involve reading source files, processing them, and writing the output to new files.</span></span> <span data-ttu-id="65419-121">選項包括在 Azure Data Lake Analytics 中執行 U-SQL 作業、在 HDInsight Hadoop 叢集中使用 Hive、Pig 或自訂的 Map/Reduce 作業，或是在 HDInsight Spark 叢集中使用 Java、Scala 或 Python 程式。</span><span class="sxs-lookup"><span data-stu-id="65419-121">Options include running U-SQL jobs in Azure Data Lake Analytics, using Hive, Pig, or custom Map/Reduce jobs in an HDInsight Hadoop cluster, or using Java, Scala, or Python programs in an HDInsight Spark cluster.</span></span>

- <span data-ttu-id="65419-122">**即時訊息擷取**：如果解決方案中包含即時來源，則架構中必須有方法可擷取和儲存即時訊息以進行串流處理。</span><span class="sxs-lookup"><span data-stu-id="65419-122">**Real-time message ingestion**: If the solution includes real-time sources, the architecture must include a way to capture and store real-time messages for stream processing.</span></span> <span data-ttu-id="65419-123">這可能是簡單的資料存放區，內送訊息會放入資料夾處理。</span><span class="sxs-lookup"><span data-stu-id="65419-123">This might be a simple data store, where incoming messages are dropped into a folder for processing.</span></span> <span data-ttu-id="65419-124">不過，許多解決方案需要有訊息擷取存放區，以做為訊息的緩衝區，以及支援相應放大處理、可靠的傳遞和其他訊息佇列語意。</span><span class="sxs-lookup"><span data-stu-id="65419-124">However, many solutions need a message ingestion store to act as a buffer for messages, and to support scale-out processing, reliable delivery, and other message queuing semantics.</span></span> <span data-ttu-id="65419-125">選項包括 Azure 事件中樞、Azure IoT 中樞和 Kafka。</span><span class="sxs-lookup"><span data-stu-id="65419-125">Options include Azure Event Hubs, Azure IoT Hubs, and Kafka.</span></span>

- <span data-ttu-id="65419-126">**串流處理**：在擷取即時訊息後，解決方案必須經由篩選、彙總和準備要分析的資料，以便處理這些資料。</span><span class="sxs-lookup"><span data-stu-id="65419-126">**Stream processing**: After capturing real-time messages, the solution must process them by filtering, aggregating, and otherwise preparing the data for analysis.</span></span> <span data-ttu-id="65419-127">已處理的串流資料接著會寫入至輸出接收器。</span><span class="sxs-lookup"><span data-stu-id="65419-127">The processed stream data is then written to an output sink.</span></span> <span data-ttu-id="65419-128">Azure 串流分析會根據永久執行的 SQL 查詢 (會針對未繫結資料流進行操作) 提供受控串流處理服務。</span><span class="sxs-lookup"><span data-stu-id="65419-128">Azure Stream Analytics provides a managed stream processing service based on perpetually running SQL queries that operate on unbounded streams.</span></span> <span data-ttu-id="65419-129">您也可以使用開放原始碼的 Apache 串流技術，例如 HDInsight 叢集中的 Storm 和 Spark 串流。</span><span class="sxs-lookup"><span data-stu-id="65419-129">You can also use open source Apache streaming technologies like Storm and Spark Streaming in an HDInsight cluster.</span></span>

- <span data-ttu-id="65419-130">**分析資料存放區**：許多巨量資料解決方案會準備資料以供分析，然後以可使用分析工具來查詢的結構化格式提供處理過的資料。</span><span class="sxs-lookup"><span data-stu-id="65419-130">**Analytical data store**: Many big data solutions prepare data for analysis and then serve the processed data in a structured format that can be queried using analytical tools.</span></span> <span data-ttu-id="65419-131">用來提供這些查詢的分析資料存放區可以是 Kimball 樣式的關聯式資料倉儲，如同我們在大部分的傳統商業智慧 (BI) 解決方案所看見的。</span><span class="sxs-lookup"><span data-stu-id="65419-131">The analytical data store used to serve these queries can be a Kimball-style relational data warehouse, as seen in most traditional business intelligence (BI) solutions.</span></span> <span data-ttu-id="65419-132">或者，我們也可以透過低延遲的 NoSQL 技術 (例如 HBase) 或是互動式 Hive 資料庫 (可針對分散式資料存放區中的資料檔案提供中繼資料擷取) 來呈現資料。</span><span class="sxs-lookup"><span data-stu-id="65419-132">Alternatively, the data could be presented through a low-latency NoSQL technology such as HBase, or an interactive Hive database that provides a metadata abstraction over data files in the distributed data store.</span></span> <span data-ttu-id="65419-133">Azure SQL 資料倉儲可提供受控服務供大規模的雲端式資料倉儲使用。</span><span class="sxs-lookup"><span data-stu-id="65419-133">Azure SQL Data Warehouse provides a managed service for large-scale, cloud-based data warehousing.</span></span> <span data-ttu-id="65419-134">HDInsight 則支援互動式 Hive、HBase 和 Spark SQL，它們也可用來提供要分析的資料。</span><span class="sxs-lookup"><span data-stu-id="65419-134">HDInsight supports Interactive Hive, HBase, and Spark SQL, which can also be used to serve data for analysis.</span></span>

- <span data-ttu-id="65419-135">**分析和報告**：大部分巨量資料解決方案的目標，是要透過分析和報告提供資料的深入見解。</span><span class="sxs-lookup"><span data-stu-id="65419-135">**Analysis and reporting**: The goal of most big data solutions is to provide insights into the data through analysis and reporting.</span></span> <span data-ttu-id="65419-136">為了讓使用者能夠分析資料，架構中可能要包括資料模型化層，例如 Azure Analysis Services 中的多維度 OLAP Cube 或表格式資料模型。</span><span class="sxs-lookup"><span data-stu-id="65419-136">To empower users to analyze the data, the architecture may include a data modeling layer, such as a multidimensional OLAP cube or tabular data model in Azure Analysis Services.</span></span> <span data-ttu-id="65419-137">架構也可能會支援自助商業智慧，其使用的是 Microsoft Power BI 或 Microsoft Excel 中的模型化和視覺效果技術。</span><span class="sxs-lookup"><span data-stu-id="65419-137">It might also support self-service BI, using the modeling and visualization technologies in Microsoft Power BI or Microsoft Excel.</span></span> <span data-ttu-id="65419-138">分析和報告也可供資料科學家或資料分析師透過互動方式瀏覽資料。</span><span class="sxs-lookup"><span data-stu-id="65419-138">Analysis and reporting can also take the form of interactive data exploration by data scientists or data analysts.</span></span> <span data-ttu-id="65419-139">針對這些案例，許多 Azure 服務支援了分析筆記本 (例如 Jupyter)，讓這些使用者能夠利用其現有的技巧來使用 Python 或 R。若要瀏覽大規模的資料，您可以使用 Microsoft R Server (不論是獨立使用或搭配 Spark 來使用)。</span><span class="sxs-lookup"><span data-stu-id="65419-139">For these scenarios, many Azure services support analytical notebooks, such as Jupyter, enabling these users to leverage their existing skills with Python or R. For large-scale data exploration, you can use Microsoft R Server, either standalone or with Spark.</span></span>

- <span data-ttu-id="65419-140">**協調流程**：大部分的巨量資料解決方案都包含重複的資料處理作業並封裝在工作流程中，這些作業會轉換來源資料、在多個來源和接收器之間移動資料、將處理過的資料載入分析資料存放區，或將結果直接推送到報告或儀表板。</span><span class="sxs-lookup"><span data-stu-id="65419-140">**Orchestration**: Most big data solutions consist of repeated data processing operations, encapsulated in workflows, that transform source data, move data between multiple sources and sinks, load the processed data into an analytical data store, or push the results straight to a report or dashboard.</span></span> <span data-ttu-id="65419-141">若要讓這些工作流程自動執行，您可以使用協調流程技術，例如 Azure Data Factory 或 Apache Oozie 和 Sqoop。</span><span class="sxs-lookup"><span data-stu-id="65419-141">To automate these workflows, you can use an orchestration technology such Azure Data Factory or Apache Oozie and Sqoop.</span></span>

<span data-ttu-id="65419-142">Azure 會納入許多可用於巨量資料架構的服務。</span><span class="sxs-lookup"><span data-stu-id="65419-142">Azure includes many services that can be used in a big data architecture.</span></span> <span data-ttu-id="65419-143">這些服務大致分為兩類：</span><span class="sxs-lookup"><span data-stu-id="65419-143">They fall roughly into two categories:</span></span>

- <span data-ttu-id="65419-144">受控服務，包括 Azure Data Lake Store、Azure Data Lake Analytics、Azure 資料倉儲、Azure 串流分析、Azure 事件中樞、Azure IoT 中樞和 Azure Data Factory。</span><span class="sxs-lookup"><span data-stu-id="65419-144">Managed services, including Azure Data Lake Store, Azure Data Lake Analytics, Azure Data Warehouse, Azure Stream Analytics, Azure Event Hub, Azure IoT Hub, and Azure Data Factory.</span></span>
- <span data-ttu-id="65419-145">以 Apache Hadoop 平台為基礎的開放原始碼技術，包括 HDFS、HBase、Hive、Pig、Spark、Storm、Oozie、Sqoop 和 Kafka。</span><span class="sxs-lookup"><span data-stu-id="65419-145">Open source technologies based on the Apache Hadoop platform, including HDFS, HBase, Hive, Pig, Spark, Storm, Oozie, Sqoop, and Kafka.</span></span> <span data-ttu-id="65419-146">在 Azure 中，您可在 Azure HDInsight 服務中使用這些技術。</span><span class="sxs-lookup"><span data-stu-id="65419-146">These technologies are available on Azure in the Azure HDInsight service.</span></span>

<span data-ttu-id="65419-147">這些選項不會互斥，而且有許多解決方案會將開放原始碼技術與 Azure 服務互相結合。</span><span class="sxs-lookup"><span data-stu-id="65419-147">These options are not mutually exclusive, and many solutions combine open source technologies with Azure services.</span></span>

## <a name="when-to-use-this-architecture"></a><span data-ttu-id="65419-148">使用此架構的時機</span><span class="sxs-lookup"><span data-stu-id="65419-148">When to use this architecture</span></span>

<span data-ttu-id="65419-149">當您有下列需求時，請考慮使用此架構樣式：</span><span class="sxs-lookup"><span data-stu-id="65419-149">Consider this architecture style when you need to:</span></span>

- <span data-ttu-id="65419-150">要儲存和處理的資料數量對於傳統資料庫來說太大時。</span><span class="sxs-lookup"><span data-stu-id="65419-150">Store and process data in volumes too large for a traditional database.</span></span>
- <span data-ttu-id="65419-151">要轉換非結構化資料以進行分析和報告。</span><span class="sxs-lookup"><span data-stu-id="65419-151">Transform unstructured data for analysis and reporting.</span></span>
- <span data-ttu-id="65419-152">要以即時或低延遲的方式擷取、處理和分析未繫結的資料串流。</span><span class="sxs-lookup"><span data-stu-id="65419-152">Capture, process, and analyze unbounded streams of data in real time, or with low latency.</span></span>
- <span data-ttu-id="65419-153">要使用 Azure Machine Learning 或 Microsoft 認知服務。</span><span class="sxs-lookup"><span data-stu-id="65419-153">Use Azure Machine Learning or Microsoft Cognitive Services.</span></span>

## <a name="benefits"></a><span data-ttu-id="65419-154">優點</span><span class="sxs-lookup"><span data-stu-id="65419-154">Benefits</span></span>

- <span data-ttu-id="65419-155">**技術選擇**。</span><span class="sxs-lookup"><span data-stu-id="65419-155">**Technology choices**.</span></span> <span data-ttu-id="65419-156">您可以在 HDInsight 叢集混合使用 Azure 受控服務和 Apache 技術，以利用現有的技術或技術投資。</span><span class="sxs-lookup"><span data-stu-id="65419-156">You can mix and match Azure managed services and Apache technologies in HDInsight clusters, to capitalize on existing skills or technology investments.</span></span>
- <span data-ttu-id="65419-157">**透過平行處理原則獲得效能**。</span><span class="sxs-lookup"><span data-stu-id="65419-157">**Performance through parallelism**.</span></span> <span data-ttu-id="65419-158">巨量資料解決方案會利用平行處理原則，來實現規模可應付大量資料的高效能解決方案。</span><span class="sxs-lookup"><span data-stu-id="65419-158">Big data solutions take advantage of parallelism, enabling high-performance solutions that scale to large volumes of data.</span></span>
- <span data-ttu-id="65419-159">**彈性調整**。</span><span class="sxs-lookup"><span data-stu-id="65419-159">**Elastic scale**.</span></span> <span data-ttu-id="65419-160">巨量資料架構中的所有元件都支援相應放大佈建，因此您可以將您的解決方案調整為支援小型或大型工作負載，只針對您所使用的資源支付費用。</span><span class="sxs-lookup"><span data-stu-id="65419-160">All of the components in the big data architecture support scale-out provisioning, so that you can adjust your solution to small or large workloads, and pay only for the resources that you use.</span></span>
- <span data-ttu-id="65419-161">**與現有解決方案互通**。</span><span class="sxs-lookup"><span data-stu-id="65419-161">**Interoperability with existing solutions**.</span></span> <span data-ttu-id="65419-162">巨量資料架構的元件也可用於 IoT 處理和企業 BI 解決方案，讓您建立可跨資料工作負載來進行作業的整合式解決方案。</span><span class="sxs-lookup"><span data-stu-id="65419-162">The components of the big data architecture are also used for IoT processing and enterprise BI solutions, enabling you to create an integrated solution across data workloads.</span></span>

## <a name="challenges"></a><span data-ttu-id="65419-163">挑戰</span><span class="sxs-lookup"><span data-stu-id="65419-163">Challenges</span></span>

- <span data-ttu-id="65419-164">**複雜度**。</span><span class="sxs-lookup"><span data-stu-id="65419-164">**Complexity**.</span></span> <span data-ttu-id="65419-165">巨量資料解決方案相當複雜，內含許多元件以便處理從多個資料來源擷取資料的作業。</span><span class="sxs-lookup"><span data-stu-id="65419-165">Big data solutions can be extremely complex, with numerous components to handle data ingestion from multiple data sources.</span></span> <span data-ttu-id="65419-166">建置、測試和疑難排解巨量資料處理程序並不容易。</span><span class="sxs-lookup"><span data-stu-id="65419-166">It can be challenging to build, test, and troubleshoot big data processes.</span></span> <span data-ttu-id="65419-167">此外，可能還要跨多個系統進行大量設定，因為您必須使用這些系統才能獲得最佳效能。</span><span class="sxs-lookup"><span data-stu-id="65419-167">Moreover, there may be a large number of configuration settings across multiple systems that must be used in order to optimize performance.</span></span>
- <span data-ttu-id="65419-168">**技能集**。</span><span class="sxs-lookup"><span data-stu-id="65419-168">**Skillset**.</span></span> <span data-ttu-id="65419-169">許多巨量資料技術都是極為專門的，會使用較為一般的應用程式架構所不常使用的框架和語言。</span><span class="sxs-lookup"><span data-stu-id="65419-169">Many big data technologies are highly specialized, and use frameworks and languages that are not typical of more general application architectures.</span></span> <span data-ttu-id="65419-170">另一方面，巨量資料技術會發展新的 API 並以更知名的語言為基礎來建置。</span><span class="sxs-lookup"><span data-stu-id="65419-170">On the other hand, big data technologies are evolving new APIs that build on more established languages.</span></span> <span data-ttu-id="65419-171">例如，Azure Data Lake Analytics 中的 U-SQL 語言是以 Transact-SQL 和 C# 兩相結合為基礎。</span><span class="sxs-lookup"><span data-stu-id="65419-171">For example, the U-SQL language in Azure Data Lake Analytics is based on a combination of Transact-SQL and C#.</span></span> <span data-ttu-id="65419-172">同樣地，SQL 型 API 適用於 Hive、HBase 和 Spark。</span><span class="sxs-lookup"><span data-stu-id="65419-172">Similarly, SQL-based APIs are available for Hive, HBase, and Spark.</span></span>
- <span data-ttu-id="65419-173">**技術成熟度**。</span><span class="sxs-lookup"><span data-stu-id="65419-173">**Technology maturity**.</span></span> <span data-ttu-id="65419-174">巨量資料中所使用的諸多技術會不斷進化。</span><span class="sxs-lookup"><span data-stu-id="65419-174">Many of the technologies used in big data are evolving.</span></span> <span data-ttu-id="65419-175">雖然核心的 Hadoop 技術 (例如 Hive 和 Pig) 已穩定下來，但 Spark 之類的新興技術會在它的每個新版本中引進大量變更和增強功能。</span><span class="sxs-lookup"><span data-stu-id="65419-175">While core Hadoop technologies such as Hive and Pig have stabilized, emerging technologies such as Spark introduce extensive changes and enhancements with each new release.</span></span> <span data-ttu-id="65419-176">相較於其他 Azure 服務，Azure Data Lake Analytics 和 Azure Data Factory 等受控服務發展時間相對較短，因此很可能會隨著時間而不斷進化。</span><span class="sxs-lookup"><span data-stu-id="65419-176">Managed services such as Azure Data Lake Analytics and Azure Data Factory are relatively young, compared with other Azure services, and will likely evolve over time.</span></span>
- <span data-ttu-id="65419-177">**安全性**。</span><span class="sxs-lookup"><span data-stu-id="65419-177">**Security**.</span></span> <span data-ttu-id="65419-178">巨量資料解決方案通常依賴將所有靜態資料儲存在集中的資料湖中。</span><span class="sxs-lookup"><span data-stu-id="65419-178">Big data solutions usually rely on storing all static data in a centralized data lake.</span></span> <span data-ttu-id="65419-179">要保護這項資料的存取權並不容易，尤其是在必須由多個應用程式和平台擷取並取用這項資料時。</span><span class="sxs-lookup"><span data-stu-id="65419-179">Securing access to this data can be challenging, especially when the data must be ingested and consumed by multiple applications and platforms.</span></span>

## <a name="best-practices"></a><span data-ttu-id="65419-180">最佳作法</span><span class="sxs-lookup"><span data-stu-id="65419-180">Best practices</span></span>

- <span data-ttu-id="65419-181">**利用平行處理原則**。</span><span class="sxs-lookup"><span data-stu-id="65419-181">**Leverage parallelism**.</span></span> <span data-ttu-id="65419-182">大多數的巨量資料處理技術會將工作負載分散到多個處理單元。</span><span class="sxs-lookup"><span data-stu-id="65419-182">Most big data processing technologies distribute the workload across multiple processing units.</span></span> <span data-ttu-id="65419-183">靜態資料檔案必須以可分割的格式建立並儲存，才能予以分散。</span><span class="sxs-lookup"><span data-stu-id="65419-183">This requires that static data files are created and stored in a splittable format.</span></span> <span data-ttu-id="65419-184">HDFS 之類的分散式檔案系統可以將讀取和寫入的效能最佳化，並由多個叢集節點以平行方式進行實際的處理，以便減少整體作業時間。</span><span class="sxs-lookup"><span data-stu-id="65419-184">Distributed file systems such as HDFS can optimize read and write performance, and the actual processing is performed by multiple cluster nodes in parallel, which reduces overall job times.</span></span>

- <span data-ttu-id="65419-185">**分割資料**。</span><span class="sxs-lookup"><span data-stu-id="65419-185">**Partition data**.</span></span> <span data-ttu-id="65419-186">批次處理通常會以週期性排程進行，例如每週或每月。</span><span class="sxs-lookup"><span data-stu-id="65419-186">Batch processing usually happens on a recurring schedule &mdash; for example, weekly or monthly.</span></span> <span data-ttu-id="65419-187">請根據符合處理排程的時態性期間分割資料檔案和資料結構，例如資料表。</span><span class="sxs-lookup"><span data-stu-id="65419-187">Partition data files, and data structures such as tables, based on temporal periods that match the processing schedule.</span></span> <span data-ttu-id="65419-188">這麼做可簡化資料擷取和作業排程，並可讓您更輕鬆地針對失敗進行疑難排解。</span><span class="sxs-lookup"><span data-stu-id="65419-188">That simplifies data ingestion and job scheduling, and makes it easier to troubleshoot failures.</span></span> <span data-ttu-id="65419-189">此外，對 Hive、U-SQL 或 SQL 查詢中使用的資料表進行分割還能大幅改進查詢效能。</span><span class="sxs-lookup"><span data-stu-id="65419-189">Also, partitioning tables that are used in Hive, U-SQL, or SQL queries can significantly improve query performance.</span></span>

- <span data-ttu-id="65419-190">**套用「讀取時的結構描述」語意**。</span><span class="sxs-lookup"><span data-stu-id="65419-190">**Apply schema-on-read semantics**.</span></span> <span data-ttu-id="65419-191">使用資料湖可讓您結合多種格式之檔案所使用的儲存體，不論這些格式是結構化、半結構化還是非結構化。</span><span class="sxs-lookup"><span data-stu-id="65419-191">Using a data lake lets you to combine storage for files in multiple formats, whether structured, semi-structured, or unstructured.</span></span> <span data-ttu-id="65419-192">請使用「讀取時的結構描述」語意，這種語意會在處理資料時 (而非在儲存資料時) 將結構描述投影至資料。</span><span class="sxs-lookup"><span data-stu-id="65419-192">Use *schema-on-read* semantics, which project a schema onto the data when the data is processing, not when the data is stored.</span></span> <span data-ttu-id="65419-193">這會讓解決方案獲得彈性，並防止資料擷取期間因為資料驗證和類型檢查所造成的瓶頸。</span><span class="sxs-lookup"><span data-stu-id="65419-193">This builds flexibility into the solution, and prevents bottlenecks during data ingestion caused by data validation and type checking.</span></span>

- <span data-ttu-id="65419-194">**就地處理資料**。</span><span class="sxs-lookup"><span data-stu-id="65419-194">**Process data in-place**.</span></span> <span data-ttu-id="65419-195">傳統的 BI 解決方案通常會使用擷取、轉換和載入 (ETL) 程序將資料移到資料倉儲。</span><span class="sxs-lookup"><span data-stu-id="65419-195">Traditional BI solutions often use an extract, transform, and load (ETL) process to move data into a data warehouse.</span></span> <span data-ttu-id="65419-196">擁有較大量資料和格式種類更多的巨量資料解決方案，則一般會使用 ETL 的變化形式，例如轉換、擷取和載入 (TEL)。</span><span class="sxs-lookup"><span data-stu-id="65419-196">With larger volumes data, and a greater variety of formats, big data solutions generally use variations of ETL, such as transform, extract, and load (TEL).</span></span> <span data-ttu-id="65419-197">在使用這個方法時，資料會在分散式的資料存放區中處理，轉換為必要結構，然後再將轉換後的資料移到分析資料存放區中。</span><span class="sxs-lookup"><span data-stu-id="65419-197">With this approach, the data is processed within the distributed data store, transforming it to the required structure, before moving the transformed data into an analytical data store.</span></span>

- <span data-ttu-id="65419-198">**在使用量和時間成本之間取得平衡**。</span><span class="sxs-lookup"><span data-stu-id="65419-198">**Balance utilization and time costs**.</span></span> <span data-ttu-id="65419-199">對於批次處理作業，請務必考慮兩個因素：計算節點的單位成本，以及使用這些節點來完成作業的每分鐘成本。</span><span class="sxs-lookup"><span data-stu-id="65419-199">For batch processing jobs, it's important to consider two factors: The per-unit cost of the compute nodes, and the per-minute cost of using those nodes to complete the job.</span></span> <span data-ttu-id="65419-200">例如，批次作業可能需要使用四個叢集節點花費八個小時的時間來完成。</span><span class="sxs-lookup"><span data-stu-id="65419-200">For example, a batch job may take eight hours with four cluster nodes.</span></span> <span data-ttu-id="65419-201">但結果可能是，該項作業只在前兩個小時用到這四個節點，之後就只需要兩個節點。</span><span class="sxs-lookup"><span data-stu-id="65419-201">However, it might turn out that the job uses all four nodes only during the first two hours, and after that, only two nodes are required.</span></span> <span data-ttu-id="65419-202">在此情況下，於兩個節點上執行整個作業會增加總作業時間，但不會讓時間加倍，因此總成本會比較少。</span><span class="sxs-lookup"><span data-stu-id="65419-202">In that case, running the entire job on two nodes would increase the total job time, but would not double it, so the total cost would be less.</span></span> <span data-ttu-id="65419-203">在某些商務案例中，使用者可能寧願花費較長的處理時間，也不願使用未充分利用的叢集資源而付出較高的成本。</span><span class="sxs-lookup"><span data-stu-id="65419-203">In some business scenarios, a longer processing time may be preferable to the higher cost of using under-utilized cluster resources.</span></span>

- <span data-ttu-id="65419-204">**叢集資源**。</span><span class="sxs-lookup"><span data-stu-id="65419-204">**Separate cluster resources**.</span></span> <span data-ttu-id="65419-205">在部署 HDInsight 叢集時，您一般可以藉由為每種類型的工作負載佈建個別的叢集資源，而實現更好的效能。</span><span class="sxs-lookup"><span data-stu-id="65419-205">When deploying HDInsight clusters, you will normally achieve better performance by provisioning separate cluster resources for each type of workload.</span></span> <span data-ttu-id="65419-206">例如，雖然 Spark 叢集會納入 Hive，但如果您需要使用 Hive 和 Spark 來執行廣泛的處理，請考慮部署個別的專用 Spark 和 Hadoop 叢集。</span><span class="sxs-lookup"><span data-stu-id="65419-206">For example, although Spark clusters include Hive, if you need to perform extensive processing with both Hive and Spark, you should consider deploying separate dedicated Spark and Hadoop clusters.</span></span> <span data-ttu-id="65419-207">同樣地，如果您要使用 HBase 和 Storm 來處理低延遲的串流處理，並使用 Hive 來進行批次處理，請考慮為 Storm、HBase 和 Hadoop 部署個別的叢集。</span><span class="sxs-lookup"><span data-stu-id="65419-207">Similarly, if you are using HBase and Storm for low latency stream processing and Hive for batch processing, consider separate clusters for Storm, HBase, and Hadoop.</span></span>

- <span data-ttu-id="65419-208">**協調資料擷取**。</span><span class="sxs-lookup"><span data-stu-id="65419-208">**Orchestrate data ingestion**.</span></span> <span data-ttu-id="65419-209">在某些情況下，現有的商務應用程式可能會直接在 Azure 儲存體 Blob 容器中撰寫要進行批次處理的資料檔案，讓這些檔案在其中供 HDInsight 或 Azure Data Lake Analytics 取用。</span><span class="sxs-lookup"><span data-stu-id="65419-209">In some cases, existing business applications may write data files for batch processing directly into Azure storage blob containers, where they can be consumed by HDInsight or Azure Data Lake Analytics.</span></span> <span data-ttu-id="65419-210">不過，您通常需要協調從內部部署或外部資料來源將資料擷取到資料湖的作業。</span><span class="sxs-lookup"><span data-stu-id="65419-210">However, you will often need to orchestrate the ingestion of data from on-premises or external data sources into the data lake.</span></span> <span data-ttu-id="65419-211">請使用協調工作流程或管線 (例如 Azure Data Factory 或 Oozie 所支援的項目)，以可預測且可集中管理的方式達到這個目的。</span><span class="sxs-lookup"><span data-stu-id="65419-211">Use an orchestration workflow or pipeline, such as those supported by Azure Data Factory or Oozie, to achieve this in a predictable and centrally manageable fashion.</span></span>

- <span data-ttu-id="65419-212">**及早刪除敏感性資料**。</span><span class="sxs-lookup"><span data-stu-id="65419-212">**Scrub sensitive data early**.</span></span> <span data-ttu-id="65419-213">資料擷取工作流程應該在程序中及早刪除敏感性資料，以免將資料儲存到資料湖。</span><span class="sxs-lookup"><span data-stu-id="65419-213">The data ingestion workflow should scrub sensitive data early in the process, to avoid storing it in the data lake.</span></span>

## <a name="iot-architecture"></a><span data-ttu-id="65419-214">IoT 架構</span><span class="sxs-lookup"><span data-stu-id="65419-214">IoT architecture</span></span>

<span data-ttu-id="65419-215">物聯網 (IoT) 是巨量資料解決方案的特定子集。</span><span class="sxs-lookup"><span data-stu-id="65419-215">Internet of Things (IoT) is a specialized subset of big data solutions.</span></span> <span data-ttu-id="65419-216">下圖顯示 IoT 可能的邏輯架構。</span><span class="sxs-lookup"><span data-stu-id="65419-216">The following diagram shows a possible logical architecture for IoT.</span></span> <span data-ttu-id="65419-217">此圖強調架構的事件串流元件。</span><span class="sxs-lookup"><span data-stu-id="65419-217">The diagram emphasizes the event-streaming components of the architecture.</span></span>

![](./images/iot.png)

<span data-ttu-id="65419-218">**雲端閘道**會使用可靠、低延遲的傳訊系統在雲端邊界擷取裝置事件。</span><span class="sxs-lookup"><span data-stu-id="65419-218">The **cloud gateway** ingests device events at the cloud boundary, using a reliable, low latency messaging system.</span></span>

<span data-ttu-id="65419-219">裝置可能會將事件直接傳送到雲端閘道，或透過**現場閘道**來傳送。</span><span class="sxs-lookup"><span data-stu-id="65419-219">Devices might send events directly to the cloud gateway, or through a **field gateway**.</span></span> <span data-ttu-id="65419-220">現場閘道是專用的裝置或軟體，通常會與裝置共置，以便接收事件並將它們轉送到雲端閘道。</span><span class="sxs-lookup"><span data-stu-id="65419-220">A field gateway is a specialized device or software, usually colocated with the devices, that receives events and forwards them to the cloud gateway.</span></span> <span data-ttu-id="65419-221">現場閘道可能也會前置處理未經處理的裝置事件，以執行篩選、彙總或通訊協定轉換等功能。</span><span class="sxs-lookup"><span data-stu-id="65419-221">The field gateway might also preprocess the raw device events, performing functions such as filtering, aggregation, or protocol transformation.</span></span>

<span data-ttu-id="65419-222">在擷取之後，事件會通過一個或多個**串流處理器**，這些處理器可以路由傳送資料 (例如，傳送到儲存體) 或執行分析和其他處理。</span><span class="sxs-lookup"><span data-stu-id="65419-222">After ingestion, events go through one or more **stream processors** that can route the data (for example, to storage) or perform analytics and other processing.</span></span>

<span data-ttu-id="65419-223">以下是一些常見的處理類型。</span><span class="sxs-lookup"><span data-stu-id="65419-223">The following are some common types of processing.</span></span> <span data-ttu-id="65419-224">(此清單一定不怎麼詳盡)。</span><span class="sxs-lookup"><span data-stu-id="65419-224">(This list is certainly not exhaustive.)</span></span>

- <span data-ttu-id="65419-225">將事件資料寫入冷儲存體，以便封存或批次分析。</span><span class="sxs-lookup"><span data-stu-id="65419-225">Writing event data to cold storage, for archiving or batch analytics.</span></span>

- <span data-ttu-id="65419-226">最忙碌路徑分析，(近乎) 即時地分析事件串流，以偵測異常行為、辨識滾動時間範圍的模式，或在串流中發生特定情況時觸發警示。</span><span class="sxs-lookup"><span data-stu-id="65419-226">Hot path analytics, analyzing the event stream in (near) real time, to detect anomalies, recognize patterns over rolling time windows, or trigger alerts when a specific condition occurs in the stream.</span></span> 

- <span data-ttu-id="65419-227">處理裝置中特殊的非遙測訊息類型，例如通知和警示。</span><span class="sxs-lookup"><span data-stu-id="65419-227">Handling special types of non-telemetry messages from devices, such as notifications and alarms.</span></span> 

- <span data-ttu-id="65419-228">機器學習。</span><span class="sxs-lookup"><span data-stu-id="65419-228">Machine learning.</span></span>

<span data-ttu-id="65419-229">深灰色的方塊顯示的是 IoT 系統中，與事件串流沒有直接關係，但為求完整所以在此納入的元件。</span><span class="sxs-lookup"><span data-stu-id="65419-229">The boxes that are shaded gray show components of an IoT system that are not directly related to event streaming, but are included here for completeness.</span></span>

- <span data-ttu-id="65419-230">**裝置登錄**是已佈建之裝置的資料庫，包括裝置識別碼，且通常會包括裝置中繼資料，例如位置。</span><span class="sxs-lookup"><span data-stu-id="65419-230">The **device registry** is a database of the provisioned devices, including the device IDs and usually device metadata, such as location.</span></span>

- <span data-ttu-id="65419-231">**佈建 API** 是常見用於佈建和註冊新裝置的外部介面。</span><span class="sxs-lookup"><span data-stu-id="65419-231">The **provisioning API** is a common external interface for provisioning and registering new devices.</span></span>

- <span data-ttu-id="65419-232">某些 IoT 解決方案允許將**命令和控制訊息**傳送至裝置。</span><span class="sxs-lookup"><span data-stu-id="65419-232">Some IoT solutions allow **command and control messages** to be sent to devices.</span></span>

> <span data-ttu-id="65419-233">本節提供了極為高階的 IoT 檢視，其中有許多要考慮的微妙之處和挑戰。</span><span class="sxs-lookup"><span data-stu-id="65419-233">This section has presented a very high-level view of IoT, and there are many subtleties and challenges to consider.</span></span> <span data-ttu-id="65419-234">如需更詳細的參考架構和討論，請參閱 [Microsoft Azure IoT 參考架構][ iot-ref-arch] (PDF 下載)。</span><span class="sxs-lookup"><span data-stu-id="65419-234">For a more detailed reference architecture and discussion, see the [Microsoft Azure IoT Reference Architecture][iot-ref-arch] (PDF download).</span></span>

 <!-- links -->

[iot-ref-arch]: https://azure.microsoft.com/updates/microsoft-azure-iot-reference-architecture-available/
